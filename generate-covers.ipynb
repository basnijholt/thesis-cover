{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import random\n",
    "\n",
    "import adaptive\n",
    "import matplotlib\n",
    "import matplotlib.cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.patheffects as patheffects\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as mtri\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def get_cmap(cmap, min_clip=0.0, max_clip=1.0, exp=1.0):\n",
    "    fcmap = getattr(plt.cm, cmap)\n",
    "    return colors.LinearSegmentedColormap.from_list(\n",
    "        \"my_colormap\", fcmap(np.linspace(min_clip, max_clip, 256) ** exp),\n",
    "    )\n",
    "\n",
    "\n",
    "def learner_till(till, learner, data):\n",
    "    new_learner = adaptive.Learner2D(None, bounds=learner.bounds)\n",
    "    new_learner.data = {k: v for k, v in data[:till]}\n",
    "    for x, y in learner._bounds_points:\n",
    "        # always include the bounds\n",
    "        new_learner.tell((x, y), learner.data[x, y])\n",
    "    return new_learner\n",
    "\n",
    "\n",
    "def plot_tri(learner, ax, xy_size):\n",
    "    ip = learner.ip()\n",
    "    tri = ip.tri\n",
    "    xs, ys = tri.points.T\n",
    "    x_size, y_size = xy_size\n",
    "    triang = mtri.Triangulation(x_size * xs, y_size * ys, triangles=tri.vertices)\n",
    "    return ax.triplot(triang, c=\"k\", lw=0.3, alpha=1, zorder=2), (ip.values, triang)\n",
    "\n",
    "\n",
    "def to_gradient(data, horizontal, cmap, spread=20, mid=0.5):\n",
    "    n, m = data.shape if horizontal else data.shape[::-1]\n",
    "    x = np.linspace(1, 0, n)\n",
    "    x = 1 / (np.exp((x - mid) * spread) + 1)  # Fermi-Dirac like\n",
    "    gradient = x.reshape(1, -1).repeat(m, 0)\n",
    "    if not horizontal:\n",
    "        gradient = gradient.T\n",
    "    gradient_rgb = cmap(data)\n",
    "    gradient_rgb[:, :, -1] = gradient\n",
    "    return gradient_rgb\n",
    "\n",
    "\n",
    "def get_new_artists(npoints_tri, learner, data, ax, xy_size, npoints_interp, cmap):\n",
    "    new_learner = learner_till(npoints_tri, learner, data)\n",
    "    (line1, line2), (zs, triang) = plot_tri(new_learner, ax, xy_size)\n",
    "    data = learner.interpolated_on_grid(npoints_interp)[\n",
    "        -1\n",
    "    ]  # This uses the original learner!\n",
    "    x_size, y_size = xy_size\n",
    "    im = ax.imshow(\n",
    "        to_gradient(np.rot90(data), horizontal=False, cmap=cmap),\n",
    "        extent=(-0.5 * x_size, 0.5 * x_size, -0.5 * y_size, 0.5 * y_size),\n",
    "        zorder=3,\n",
    "    )\n",
    "    ax.tripcolor(triang, zs.flatten(), zorder=0, cmap=cmap)\n",
    "    return im, line1, line2\n",
    "\n",
    "\n",
    "def generate_cover(\n",
    "    learner,\n",
    "    save_fname: Optional[str] = \"thesis-cover.pdf\",\n",
    "    with_lines=False,\n",
    "    npoints_interp=1000,\n",
    "    dpi=300,\n",
    "    cmap=None,\n",
    "    personal_text=None,\n",
    "    edition=None,\n",
    "    with_text=True,\n",
    "):\n",
    "    data = list(learner.data.items())\n",
    "\n",
    "    # Measured from proefdruk\n",
    "    x_total = 34.95  # cm total sides + back\n",
    "    y_total = 24  # cm top to bottom\n",
    "\n",
    "    inch_per_cm = 2.54\n",
    "    margin = 0.5  # add 5 mm margin on each side\n",
    "\n",
    "    x_size = (x_total + margin) / inch_per_cm\n",
    "    y_size = (y_total + margin) / inch_per_cm\n",
    "    xy_size = x_size, y_size\n",
    "\n",
    "    spine_size = 1.1 / inch_per_cm\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(x_size, y_size))\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    cmap = cmap or get_cmap(\"inferno\", 0.15, 0.95, 1.15)\n",
    "    npoints_tri = len(data) // 4\n",
    "    if len(data) > 4000:\n",
    "        npoints_tri = max(npoints_tri, 4000)\n",
    "\n",
    "    im, line1, line2 = get_new_artists(\n",
    "        npoints_tri, learner, data, ax, xy_size, npoints_interp, cmap\n",
    "    )\n",
    "\n",
    "    title = \"Towards realistic numerical simulations \\n of Majorana devices\"\n",
    "    title2 = \"Towards realistic numerical simulations of Majorana devices\"\n",
    "    author = \"Bas Nijholt\"\n",
    "\n",
    "    text_color = \"white\"\n",
    "\n",
    "    ax.axis(\"off\")\n",
    "    if with_text:\n",
    "        font = \"proxima_ssv/ProximaNova-Regular.otf\"\n",
    "        text_kwargs = dict(\n",
    "            path_effects=[\n",
    "                patheffects.withStroke(\n",
    "                    linewidth=0.7, foreground=\"black\", capstyle=\"round\", alpha=1\n",
    "                )\n",
    "            ],\n",
    "            zorder=4,\n",
    "            verticalalignment=\"center\",\n",
    "            fontproperties=fm.FontProperties(fname=font),\n",
    "        )\n",
    "        for pos, text in zip([-0.8, 0.7], [author, title]):\n",
    "            ax.text(\n",
    "                x_size / 4,\n",
    "                pos * (y_size - margin) / 2,\n",
    "                text.upper(),\n",
    "                color=text_color,\n",
    "                weight=\"bold\",\n",
    "                **text_kwargs,\n",
    "                horizontalalignment=\"center\",\n",
    "                fontsize=18,\n",
    "            )\n",
    "\n",
    "        ax.text(\n",
    "            -0.09,\n",
    "            y_size / 4 - 0.9,\n",
    "            title2,\n",
    "            color=text_color,\n",
    "            weight=\"bold\",\n",
    "            rotation=-90,\n",
    "            **text_kwargs,\n",
    "            fontsize=12,\n",
    "            horizontalalignment=\"left\",\n",
    "        )\n",
    "        ax.text(\n",
    "            -0.09,\n",
    "            -y_size / 4 - 1,\n",
    "            author,\n",
    "            color=text_color,\n",
    "            weight=\"bold\",\n",
    "            rotation=-90,\n",
    "            **text_kwargs,\n",
    "            fontsize=12,\n",
    "            horizontalalignment=\"left\",\n",
    "        )\n",
    "\n",
    "        lower_text_back = \"Casimir PhD series 2020-11\\nISBN 978-90-8593-438-7\"\n",
    "        if edition is not None:\n",
    "            lower_text_back += f\"\\nedition {edition} of 120\"\n",
    "        ax.text(\n",
    "            -x_size / 4,\n",
    "            -0.8 * (y_size - margin) / 2,\n",
    "            lower_text_back,\n",
    "            color=text_color,\n",
    "            weight=\"bold\",\n",
    "            horizontalalignment=\"center\",\n",
    "            **text_kwargs,\n",
    "            fontsize=11,\n",
    "        )\n",
    "        if personal_text is not None:\n",
    "            ax.text(\n",
    "                -x_size / 4,\n",
    "                0.4 * (y_size - margin) / 2,\n",
    "                personal_text,\n",
    "                color=text_color,\n",
    "                weight=\"bold\",\n",
    "                horizontalalignment=\"center\",\n",
    "                **text_kwargs,\n",
    "                fontsize=14,\n",
    "            )\n",
    "\n",
    "        if with_lines:\n",
    "            for i in [-1, +1]:\n",
    "                line_kwargs = dict(color=\"cyan\", zorder=10, linestyles=\":\")\n",
    "                ax.vlines(i * spine_size / 2, -y_size / 2, y_size / 2, **line_kwargs)\n",
    "                ax.vlines(\n",
    "                    -i * x_size / 2 + i * margin, -y_size / 2, y_size / 2, **line_kwargs\n",
    "                )\n",
    "                ax.hlines(\n",
    "                    -i * y_size / 2 + i * margin, -x_size / 2, x_size / 2, **line_kwargs\n",
    "                )\n",
    "\n",
    "    ax.set_xlim(-x_size / 2, x_size / 2)\n",
    "    ax.set_ylim(-y_size / 2, y_size / 2)\n",
    "    print(f\"Saving {save_fname}\")\n",
    "    if save_fname is not None:\n",
    "        fig.savefig(\n",
    "            save_fname,\n",
    "            format=save_fname.suffix[1:],\n",
    "            pad_inches=0,\n",
    "            dpi=dpi,\n",
    "        )\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def bounds_from_saved_learner(fname):\n",
    "    learner = adaptive.Learner2D(None, [(-1, 1), (-1, 1)])\n",
    "    learner.load(fname)\n",
    "    xs, ys = np.array(list(learner.data.keys())).T\n",
    "    bounds = [(xs.min(), xs.max()), (ys.min(), ys.max())]\n",
    "    return bounds\n",
    "\n",
    "\n",
    "def load_learner(fname=\"data/mu-sweep2/data_learner_0246.pickle\"):\n",
    "    learner = adaptive.Learner2D(None, bounds_from_saved_learner(fname))\n",
    "    learner.load(fname)\n",
    "    return learner\n",
    "\n",
    "\n",
    "def save(fname):\n",
    "    print(f\"Opening {fname}\")\n",
    "    f = fname.replace(\"/\", \"__\")[:-7]\n",
    "    pdf_fname = f\"covers/{f}.pdf\"\n",
    "    print(pdf_fname)\n",
    "    if os.path.exists(pdf_fname):\n",
    "        print(\"exists, exit!\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    learner = load_learner(fname)\n",
    "    generate_cover(learner, pdf_fname, with_lines=False, npoints_interp=2000)\n",
    "\n",
    "\n",
    "def fname_out(folder, fname):\n",
    "    fname_friendly = str(fname).replace(\"/\", \"__\")\n",
    "    return folder / f\"{fname_friendly}.pdf\"\n",
    "    \n",
    "\n",
    "options = sorted(Path(\"data\").glob(\"*/*.pickle\"))\n",
    "len(options)\n",
    "random.seed(107)  # seed chosen such that Vandersypen has the cover he wants.\n",
    "random.shuffle(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_msgs = [\n",
    "    # Family\n",
    "    \"voor papa & Yvonne\",\n",
    "    \"voor mama & Peter\",\n",
    "    \"voor opa & oma\",\n",
    "    \"till Björn\",\n",
    "    \"till Maria\",\n",
    "    \"voor Donald & Gerdie\",\n",
    "    \"voor Emma & Rik\",\n",
    "    \"voor Mirjam & Daniel\",\n",
    "    \"voor John & Jeanine\",\n",
    "    \"voor Paul & Marjolein\",\n",
    "    \"voor Jorn\",\n",
    "    \"voor Eva & Ron\",\n",
    "    \"for Marcella\",\n",
    "    \"für Volker & Renee\"\n",
    "    # Friends\n",
    "    \"till Sofie\",\n",
    "    \"voor Stijn\",\n",
    "    \"voor Jimmy & Tessa\",\n",
    "    \"voor Bram\",\n",
    "    \"voor Kaila\",\n",
    "    \"voor Maria\",\n",
    "    \"voor Michiel\",\n",
    "    \"voor Bas\",\n",
    "    \"voor Daniël\",\n",
    "    \"voor Jesse\",\n",
    "    \"voor Stijn\",\n",
    "    \"voor Michiel & Anne-Nynke\",\n",
    "    \"for Joe\",\n",
    "    # Colleagues: MS and TUD\n",
    "    \"voor Tom\",\n",
    "    \"voor Kevin\",\n",
    "    \"voor Victor\",\n",
    "    \"voor Mine\",\n",
    "    \"for Bernard\",\n",
    "    \"for Leo\",\n",
    "    \"for Martha\",\n",
    "    \"voor Willemijn\",\n",
    "    \"voor Damaz\",\n",
    "    # Quantum Tinkerer\n",
    "    \"for Piotr\",\n",
    "    \"for Satish\",\n",
    "    \"for Daniel\",\n",
    "    \"for Slava\",\n",
    "    \"for André\",\n",
    "    \"for Kim\",\n",
    "    \"for Kostas\",\n",
    "    \"for Hélène\",\n",
    "    \"for Chun-Xiao\",\n",
    "    # Ph.D. committee\n",
    "    \"for Dr. Anton Akhmerov\",\n",
    "    \"for Dr. Michael Wimmer\",\n",
    "    \"for Prof. Dr. L. M. K. Vandersypen\",\n",
    "    \"for Prof. Dr. C. W. J. Beenakker\",\n",
    "    \"for Prof. Dr. A. P. Higginbotham\",\n",
    "    \"for Prof. Dr. F. von Oppen\",\n",
    "    \"for Prof. Dr. E. Prada\",\n",
    "    \"for Prof. Dr. A. F. Otte\",\n",
    "]\n",
    "print(len(personal_msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = next(i for i, msg in enumerate(personal_msgs) if \"Vandersypen\" in msg)\n",
    "\n",
    "# for seed in range(10000):\n",
    "#     options = sorted(Path(\"data\").glob(\"*/*.pickle\"))\n",
    "#     random.seed(seed)\n",
    "#     random.shuffle(options)\n",
    "#     if options[i] == Path(\"data/mu-sweep2/data_learner_0256.pickle\"):\n",
    "#         break\n",
    "# seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import zip_longest\n",
    "\n",
    "folder = Path(\"covers\")\n",
    "folder.mkdir(exist_ok=True)\n",
    "\n",
    "for i, (fname, msg) in enumerate(zip_longest(options, personal_msgs)):\n",
    "    if fname_out(folder, fname).exists():\n",
    "        continue\n",
    "    learner = load_learner(fname)\n",
    "    print(f\"cover {i+1}, npoints: {learner.npoints}\")\n",
    "    cmap = get_cmap(\"inferno\", 0.10, 0.85, 0.85)\n",
    "    generate_cover(\n",
    "        learner,\n",
    "        fname_out(folder, fname),\n",
    "        with_lines=False,\n",
    "        cmap=cmap,\n",
    "        personal_text=msg,\n",
    "        npoints_interp=2000,\n",
    "        dpi=300,\n",
    "        edition=i + 1,\n",
    "        with_text=True,\n",
    "    )\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into single pdf command\n",
    "fnames_as_str = \" \".join([str(fname_out(folder, f)) for f in options])\n",
    "f\"pdfunite {fnames_as_str} all-covers.pdf\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
